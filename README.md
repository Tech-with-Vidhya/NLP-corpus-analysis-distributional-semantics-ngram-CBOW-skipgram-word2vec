# NLP-corpus-analysis-distributional-semantics-ngram-CBOW-skipgram-word2vec

This project is delivered as part of my Masters in Big Data Science (MSc BDS) Program for the module named “Natural Language Processing” in Queen Mary University of London (QMUL), London, United Kingdom.  

This project covers the distributional semantics to investigate how some words in the English language changed over the course of the last two centuries 2000 and 2010 using a private Corpus of Historical American English (COHA) dataset.  

The project explores and implements various sampling methods as listed below: 
1. N-Gram 
2. CBOW 
3. SkipGram 
4. Word2Vec  

**NOTE:** Due to the data privacy and the data protection policy to be adhered by the students; the datasets and the solution related code are not exposed and updated in the GitHub public profile; in order to be compliant with the Queen Mary University of London (QMUL) policies.
